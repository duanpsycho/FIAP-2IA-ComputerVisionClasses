{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correspondencia de formas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"imagens/shapes.jpg\")\n",
    "image_target = cv2.imread(\"imagens/star.jpg\")\n",
    "\n",
    "cv2.imshow(\"Fruits\", image)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.imshow(\"Target\", image_target)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "_, image_binary = cv2.threshold(image_gray, 230, 255,cv2.THRESH_BINARY_INV)\n",
    "image_gray_target = cv2.cvtColor(image_target, cv2.COLOR_BGR2GRAY)\n",
    "_, image_target_binary = cv2.threshold(image_gray_target, 230, 255,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "cv2.imshow(\"Fruits Binary\", image_binary)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.imshow(\"Target Binary\", image_target_binary)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_target_contour = image_target.copy()\n",
    "_, contour_target, hierarchy = cv2.findContours(image_target_binary,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.drawContours(image_target_contour, contour_target, 0, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Target Contour\", image_target_contour)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21697076862173215\n",
      "0.10479351156122929\n",
      "0.05397178326730856\n",
      "0.24908817898612212\n",
      "0.027009941605979915\n",
      "0.23740218637769916\n"
     ]
    }
   ],
   "source": [
    "# Match Shapes\n",
    "# 3.4.1 com os algoritmos sem a remoção da lib\n",
    "image_detected = image.copy()\n",
    "cv2.imshow(\"Detected Binary\", image_binary)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "_, contours, hierarchy = cv2.findContours(image_binary, cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for contour in contours:\n",
    "    #Quanto menor o valor mais similaridade existe\n",
    "    match_perc = cv2.matchShapes(contour_target[0], contour, 1, 0)\n",
    "    print(match_perc)\n",
    "    cv2.drawContours(image_detected, [contour], 0, (0, 0, 255), 2)\n",
    "    cv2.imshow(\"Detected\", image_detected)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()\n",
    "    if match_perc < 0.05:\n",
    "        match_contour = contour\n",
    "        cv2.drawContours(image_detected, [match_contour], 0, (0, 255, 0), 2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identificação de Retas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"imagens/campo.png\")\n",
    "\n",
    "cv2.imshow(\"Campo Futebol\", image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "image_gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "image_edges = cv2.Canny(image_gray, 100, 250, apertureSize = 3)\n",
    "image_detecada = image.copy()\n",
    "lines = cv2.HoughLines(image_edges, 1, np.pi/180, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-263.           3.0892327]]\n",
      "[[-260.           3.0892327]]\n",
      "[[-15.          3.0892327]]\n",
      "[[-18.          3.0892327]]\n",
      "[[-265.          3.106686]]\n",
      "[[-20.         3.106686]]\n",
      "[[211.          1.5184364]]\n",
      "[[28.         1.5184364]]\n",
      "[[395.          1.5184364]]\n",
      "[[398.          1.5184364]]\n",
      "[[215.          1.5184364]]\n",
      "[[30.         1.5184364]]\n"
     ]
    }
   ],
   "source": [
    "for line in lines:\n",
    "    print(line)\n",
    "    for rho, theta in line:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a*rho\n",
    "        y0 = b*rho\n",
    "        x1 = int(x0 + 1000*(-b))\n",
    "        y1 = int(y0 + 1000*(a))\n",
    "        x2 = int(x0 - 1000*(-b))\n",
    "        y2 = int(y0 - 1000*(a))\n",
    "        cv2.line(image_detecada,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "        \n",
    "cv2.imshow(\"Campo Futebol Lines\", image_detecada)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-263.           3.0892327]]\n",
      "[[-260.           3.0892327]]\n",
      "[[-15.          3.0892327]]\n",
      "[[-18.          3.0892327]]\n",
      "[[-265.          3.106686]]\n",
      "[[-20.         3.106686]]\n",
      "[[211.          1.5184364]]\n",
      "[[28.         1.5184364]]\n",
      "[[395.          1.5184364]]\n",
      "[[398.          1.5184364]]\n",
      "[[215.          1.5184364]]\n",
      "[[30.         1.5184364]]\n"
     ]
    }
   ],
   "source": [
    "for line in lines:\n",
    "    print(line)\n",
    "    for rho, theta in line:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a*rho\n",
    "        y0 = b*rho\n",
    "        x1 = int(x0 + 1000*(-b))\n",
    "        y1 = int(y0 + 1000*(a))\n",
    "        x2 = int(x0 - 1000*(-b))\n",
    "        y2 = int(y0 - 1000*(a))\n",
    "        cv2.line(image_detecada,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "        \n",
    "cv2.imshow(\"Campo Futebol Lines\", image_detecada)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correspondencia de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"imagens/mario.jpg\")\n",
    "\n",
    "cv2.imshow(\"Mario\", image)\n",
    "cv2.waitKey()\n",
    "\n",
    "image_template = cv2.imread(\"imagens/coin_mario.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "cv2.imshow(\"Moeda Template\", image_template)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "image_matched = image.copy()\n",
    "matched_template = cv2.matchTemplate(image_gray, image_template,cv2.TM_CCOEFF_NORMED)\n",
    "w, h = image_template.shape[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.9\n",
    "loc = np.where(matched_template >= threshold)\n",
    "#Índice é a informação da coordenada\n",
    "for pt in zip(*loc[::-1]):\n",
    "    cv2.rectangle(image_matched, pt, (pt[0] + w, pt[1] + h), (0,255,0), 1)\n",
    "    \n",
    "    \n",
    "cv2.imshow(\"Moeda Matched\", image_matched)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"imagens/wally.jpg\")\n",
    "\n",
    "cv2.imshow(\"Wally\", image)\n",
    "cv2.waitKey()\n",
    "\n",
    "image_template = cv2.imread(\"imagens/wally_face.jpg\",cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "cv2.imshow(\"Wally Template\", image_template)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "image_matched = image.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_template = cv2.matchTemplate(image_gray, image_template, cv2.TM_CCOEFF_NORMED)\n",
    "\n",
    "w, h = image_template.shape[::-1]\n",
    "\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(matched_template)\n",
    "top_left = max_loc\n",
    "bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "\n",
    "cv2.rectangle(image_matched, top_left, bottom_right, (0,255,0), 2)\n",
    "cv2.imshow(\"Moeda Matched\", image_matched)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio 1\n",
    "Em uma imagem de baralho completo, localize um 7 de Copas e o destaque com um retângulo, indicando com um texto acima a identificação da carta (“7 de Copas”).  \n",
    "As imagens se encontram no repositório do GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_baralho = cv2.imread(\"imagens/playing-cards.jpg\")\n",
    "\n",
    "cv2.imshow(\"Baralho\", image_baralho)\n",
    "cv2.waitKey()\n",
    "\n",
    "image_7_espada = cv2.imread(\"imagens/playing-cards-7-copas.jpg\")\n",
    "\n",
    "cv2.imshow(\"7 de Espadas\", image_7_espada)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_baralho_gray = cv2.cvtColor(image_baralho, cv2.COLOR_BGR2GRAY)\n",
    "image_7_espada_gray = cv2.cvtColor(image_7_espada, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_template = cv2.matchTemplate(image_baralho_gray, image_7_espada_gray, cv2.TM_CCOEFF_NORMED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max e Min da maior semelhança\n",
    "min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(matched_template)\n",
    "w, h = image_7_espada_gray.shape[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maior coordenada do match\n",
    "top_left = max_loc\n",
    "bottom_right = (top_left[0] + w, top_left[1] + h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.rectangle(image_baralho, top_left, bottom_right, (0, 255, 255), 2)\n",
    "\n",
    "cv2.imshow(\"Encontrado\", image_baralho)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIFT - Scale Invariance Feature Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'SIFT'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-d45329714484>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mimage_gray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0msift_detector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSIFT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mkps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msift_detector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_gray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'SIFT'"
     ]
    }
   ],
   "source": [
    "# Instalar versao 3.4.1\n",
    "\n",
    "image = cv2.imread(\"imagens/cristo.jpg\")\n",
    "cv2.imshow(\"Cristo Redentor\", image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "sift_detector = cv2.xfeatures2d.SIFT_create()\n",
    "(kps, descs) = sift_detector.detectAndCompute(image_gray, None)\n",
    "\n",
    "print(\"Pontos detectados \" + str(len(kps)))\n",
    "\n",
    "image_detected = image.copy()\n",
    "\n",
    "image_detected = cv2.drawKeypoints(image_detected, kps, image_detected,\n",
    "flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "cv2.imshow(\"Cristo Redentor Discriminant\", image_detected)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SURF - Speed Up Robust Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'xfeatures2d'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-83637b26bad9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimage_gray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msurf_detector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxfeatures2d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSURF_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msurf_detector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetHessianThreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mkps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msurf_detector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_gray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'xfeatures2d'"
     ]
    }
   ],
   "source": [
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "surf_detector = cv2.xfeatures2d.SURF_create()\n",
    "# Quando diminui o Threshold, aumenta a quantidade de pontos de interesse\n",
    "surf_detector.setHessianThreshold(5000)\n",
    "(kps, descs) = surf_detector.detectAndCompute(image_gray, None)\n",
    "\n",
    "print(\"Pontos detectados \" + str(len(kps)))\n",
    "\n",
    "image_detected = image.copy()\n",
    "\n",
    "image_detected = cv2.drawKeypoints(image_detected, kps, image_detected,\n",
    "flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "cv2.imshow(\"Cristo Redentor Discriminant\", image_detected)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAST - Feature from Accelerated Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pontos detectados 1590\n"
     ]
    }
   ],
   "source": [
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "fast_detector = cv2.FastFeatureDetector_create()\n",
    "kps = fast_detector.detect(image_gray, None)\n",
    "\n",
    "print(\"Pontos detectados \" + str(len(kps)))\n",
    "\n",
    "image_detected = image.copy()\n",
    "image_detected = cv2.drawKeypoints(image_detected, kps, image_detected,\n",
    "flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "cv2.imshow(\"Cristo Redentor Discriminant\", image_detected)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BRIEF - Binary Robust Independent Elementary Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'xfeatures2d'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-03fd7147c152>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfast_detector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFastFeatureDetector_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mbrief\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxfeatures2d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBriefDescriptorExtractor_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mkps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfast_detector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_gray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mkps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrief\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_gray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'xfeatures2d'"
     ]
    }
   ],
   "source": [
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "fast_detector = cv2.FastFeatureDetector_create()\n",
    "brief = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "kps = fast_detector.detect(image_gray, None)\n",
    "kps, desc = brief.compute(image_gray, kps)\n",
    "\n",
    "print(\"Pontos detectados \" + str(len(kps)))\n",
    "\n",
    "image_detected = image.copy()\n",
    "image_detected = cv2.drawKeypoints(image_detected, kps, image_detected,\n",
    "flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "cv2.imshow(\"Cristo Redentor Discriminant\", image_detected)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correspondencia por força bruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_target = cv2.imread(\"imagens/cristo.jpg\")\n",
    "image_target_gray = cv2.cvtColor(image_target, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "image_search = cv2.imread(\"imagens/cristo-redentor.jpg\")\n",
    "image_search_gray = cv2.cvtColor(image_search, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "orb_detector = cv2.ORB_create(5000)\n",
    "kps = orb_detector.detect(image_target_gray, None)\n",
    "kps_target, desc_target = orb_detector.compute(image_target_gray, kps)\n",
    "kps = orb_detector.detect(image_search_gray, None)\n",
    "kps_search, desc_search = orb_detector.compute(image_search_gray, kps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLANN_INDEX_LSH = 6\n",
    "\n",
    "index_params= dict(algorithm = FLANN_INDEX_LSH, table_number = 6, key_size = 12, multi_probe_level = 1)\n",
    "\n",
    "search_params = dict(checks=50)\n",
    "\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "matches = flann.knnMatch(desc_target, desc_search, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "matchesMask = [[0,0] for i in range(len(matches))]\n",
    "for i,(m,n) in enumerate(matches):\n",
    "    if m.distance < 0.7*n.distance:\n",
    "        matchesMask[i]=[1,0]\n",
    "\n",
    "draw_params = dict(matchColor = (0,255,0), singlePointColor = (255,0,0),\n",
    "matchesMask = matchesMask, flags = 0)\n",
    "image_detected = cv2.drawMatchesKnn(image_target_gray, kps_target,\n",
    "image_search_gray, kps_search, matches, None, **draw_params)\n",
    "cv2.imshow(\"Cristo Redentor Discriminant\", image_detected)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio 2\n",
    "Utilize a imagem da embalagem do iogurte, conforme a baixo, como alvo para obter suas características. Posteriormente, faça o mesmo buscando tais características em um vídeo promocional, frame a frame, para identificar o quanto da embalagem é exposto.  \n",
    "\n",
    "Aplique o algoritmo de extração de características de ORB. Para a correspondência de informações entre a embalagem e o vídeo, utilize o método de FLANN. Após testes, estabeleça um limiar de pontos de correspondência e, por meio deste valor, informe se a embalagem é detectada ou não com um texto no próprio vídeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_target = cv2.imread(\"imagens/cristo.jpg\")\n",
    "image_target_gray = cv2.cvtColor(image_target, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "image_search = cv2.imread(\"imagens/cristo-redentor.jpg\")\n",
    "image_search_gray = cv2.cvtColor(image_search, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "orb_detector = cv2.ORB_create(5000)\n",
    "\n",
    "kps = orb_detector.detect(image_target_gray, None)\n",
    "kps_target, desc_target = orb_detector.compute(image_target_gray, kps)\n",
    "\n",
    "kps = orb_detector.detect(image_search_gray, None)\n",
    "kps_search, desc_search = orb_detector.compute(image_search_gray, kps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLANN_INDEX_LSH = 6\n",
    "index_params= dict(algorithm = FLANN_INDEX_LSH, table_number = 6, key_size = 12, multi_probe_level = 1) \n",
    "\n",
    "search_params = dict(checks=50)\n",
    "\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "matches = flann.knnMatch(desc_target, desc_search, k=2)\n",
    "\n",
    "print(len(matches))\n",
    "\n",
    "# Need to draw only good matches, so create a mask\n",
    "matchesMask = [[0,0] for i in range(len(matches))]\n",
    "\n",
    "# ratio test as per Lowe's paper\n",
    "for i,(m,n) in enumerate(matches):\n",
    "    if m.distance < 0.8*n.distance:\n",
    "        matchesMask[i]=[1,0]\n",
    "        \n",
    "draw_params = dict(matchColor = (0,255,0), singlePointColor = (255,0,0), matchesMask = matchesMask, flags = 0)\n",
    "image_detected = cv2.drawMatchesKnn(image_target_gray, kps_target, image_search_gray, kps_search, matches, None, **draw_params)\n",
    "\n",
    "cv2.imshow(\"Cristo Redentor Discriminant\", image_detected)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:IBM]",
   "language": "python",
   "name": "conda-env-IBM-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
